{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93327538",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis: Solar Wind & Kp Index\n",
    "This notebook performs EDA on the Aurora project data pipeline.\n",
    "\n",
    "**Goal:** Understand the distribution, missing values, and correlations of Solar Wind (OMNI) features before training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df04c50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Data Science Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Project Specific Imports\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from src.data import (\n",
    "    fetch_omni_data,\n",
    "    fetch_kp_range,\n",
    "    clean_solarwind,\n",
    "    add_time_features,\n",
    "    add_moving_averages\n",
    ")\n",
    "\n",
    "# Configuration\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-whitegrid') # Or 'ggplot'\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deef1b0a",
   "metadata": {},
   "source": [
    "# 1. Load & Merge Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f16599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters (matching default args in build_dataset.py)\n",
    "START_YEAR = 2010\n",
    "END_YEAR = 2020\n",
    "\n",
    "logging.info(f\"Fetching historical data from {START_YEAR} to {END_YEAR}...\")\n",
    "\n",
    "# 1. Fetch Solar Wind Data (OMNI)\n",
    "try:\n",
    "    sw_df = fetch_omni_data(start_year=START_YEAR, end_year=END_YEAR)\n",
    "    logging.info(f\"Solar Wind Data shape: {sw_df.shape}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error fetching OMNI data: {e}\")\n",
    "    # Fallback if fetch fails (e.g., load from cache if you have one)\n",
    "    # sw_df = pd.read_pickle(\"data/interim/omni_cached.pkl\")\n",
    "\n",
    "# 2. Fetch Kp Index\n",
    "try:\n",
    "    kp_df = fetch_kp_range(start_year=START_YEAR, end_year=END_YEAR)\n",
    "    logging.info(f\"Kp Data shape: {kp_df.shape}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error fetching Kp data: {e}\")\n",
    "\n",
    "# 3. Merge (Simple time-based merge assumption, adjust based on actual src.data logic)\n",
    "# Assuming indices are datetime objects\n",
    "df = pd.merge(sw_df, kp_df, left_index=True, right_index=True, how='inner')\n",
    "logging.info(f\"Merged Data shape: {df.shape}\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b0e97c",
   "metadata": {},
   "source": [
    "# 2. Data Overview & Missing Values\n",
    "Look at the raw data quality before cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022517b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data Info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nSummary Statistics:\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9222aff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using missingno to visualize gaps in the time series\n",
    "plt.figure(figsize=(15, 6))\n",
    "msno.matrix(df, freq='M') # 'M' resamples to Month for readability if data is high-res\n",
    "plt.title(\"Missing Value Matrix (Time Series Gaps)\", fontsize=16)\n",
    "plt.show()\n",
    "\n",
    "# Percentage of missing values per column\n",
    "missing_percent = df.isnull().mean() * 100\n",
    "missing_percent = missing_percent[missing_percent > 0].sort_values(ascending=False)\n",
    "\n",
    "if not missing_percent.empty:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.barplot(x=missing_percent.index, y=missing_percent.values, palette='viridis')\n",
    "    plt.title(\"Percentage of Missing Data by Feature\")\n",
    "    plt.ylabel(\"Percent Missing (%)\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No missing values found (or already handled in fetch step).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedf12de",
   "metadata": {},
   "source": [
    "# 3. Distributions & Outliers\n",
    "Checking the distribution of key physical parameters (e.g., `bz`, `speed`, `density`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b28e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical columns (excluding Kp usually, which is ordinal/discrete-like)\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Plot histograms\n",
    "df[num_cols].hist(bins=50, figsize=(20, 15), layout=(5, 4), color='steelblue', edgecolor='black')\n",
    "plt.suptitle(\"Feature Distributions\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f572dd",
   "metadata": {},
   "source": [
    "# 4. Feature Engineering\n",
    "We apply the pipeline steps `clean_solarwind`, `add_time_features`, and `add_moving_averages` to see how features change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf064b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Clean\n",
    "df_clean = clean_solarwind(df)\n",
    "\n",
    "# 2. Add Time Features (Cyclical)\n",
    "df_features = add_time_features(df_clean)\n",
    "\n",
    "# 3. Add Moving Averages (This likely adds rolling means/stds)\n",
    "df_final = add_moving_averages(df_features)\n",
    "\n",
    "print(f\"Shape after feature engineering: {df_final.shape}\")\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a4f7e6",
   "metadata": {},
   "source": [
    "# 5. Correlation Analysis\n",
    "We look at how features correlate with the target (`kp`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bec4508",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_correlations(df, target_col='kp'):\n",
    "    # Select numerical columns\n",
    "    numeric_df = df.select_dtypes(include=[np.number])\n",
    "    \n",
    "    # 1. Correlation with Target\n",
    "    corr_with_target = numeric_df.corrwith(numeric_df[target_col]).sort_values(ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.barplot(x=corr_with_target.values, y=corr_with_target.index, palette='coolwarm')\n",
    "    plt.title(f\"Feature Correlation with Target ({target_col})\")\n",
    "    plt.show()\n",
    "\n",
    "    # 2. Full Heatmap\n",
    "    plt.figure(figsize=(20, 16))\n",
    "    sns.heatmap(numeric_df.corr(), annot=False, cmap='coolwarm', center=0)\n",
    "    plt.title(\"Global Correlation Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    # 3. VIF (Variance Inflation Factor) check for Multicollinearity\n",
    "    # (Handling infinite values or NaNs first if present)\n",
    "    clean_num = numeric_df.dropna().replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    \n",
    "    # Selecting a subset if too many columns (e.g., top 15 correlated)\n",
    "    top_cols = corr_with_target.head(15).index.tolist()\n",
    "    X = clean_num[top_cols].drop(columns=[target_col], errors='ignore')\n",
    "    \n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data['Feature'] = X.columns\n",
    "    vif_data['VIF'] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))]\n",
    "    \n",
    "    print(\"\\nVariance Inflation Factor (Top Correlated Features):\")\n",
    "    display(vif_data.sort_values(by='VIF', ascending=False))\n",
    "\n",
    "# Assuming 'kp' or 'Kp' is the target column name\n",
    "target_variable = 'kp' if 'kp' in df_final.columns else df_final.columns[-1]\n",
    "analyze_correlations(df_final, target_col=target_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16005cc",
   "metadata": {},
   "source": [
    "# 6. Time Series Visualization\n",
    "For Aurora data we need to visualize the time series, specifically identifying storm events (high Kp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29ee4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_storm_event(df, start_date, end_date):\n",
    "    \"\"\"Plots Solar Wind parameters and Kp index for a specific date range.\"\"\"\n",
    "    subset = df[start_date:end_date]\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(14, 10), sharex=True)\n",
    "    \n",
    "    # Plot Kp\n",
    "    if 'kp' in subset.columns:\n",
    "        sns.lineplot(data=subset, x=subset.index, y='kp', ax=axes[0], color='red', linewidth=2)\n",
    "        axes[0].set_ylabel(\"Kp Index\")\n",
    "        axes[0].set_title(f\"Geomagnetic Storm Event: {start_date} to {end_date}\")\n",
    "        axes[0].axhline(y=5, color='black', linestyle='--', label='Storm Threshold')\n",
    "        axes[0].legend()\n",
    "\n",
    "    # Plot Bz (Interplanetary Magnetic Field) - Critical for storms\n",
    "    # Adjust column name 'bz' based on your actual data schema\n",
    "    bz_col = [c for c in subset.columns if 'bz' in c.lower()]\n",
    "    if bz_col:\n",
    "        sns.lineplot(data=subset, x=subset.index, y=bz_col[0], ax=axes[1], color='blue')\n",
    "        axes[1].set_ylabel(\"Bz (nT)\")\n",
    "        axes[1].axhline(y=0, color='gray', linestyle='--', linewidth=0.5)\n",
    "\n",
    "    # Plot Speed/Density\n",
    "    # Adjust column names 'speed', 'density' based on schema\n",
    "    speed_col = [c for c in subset.columns if 'speed' in c.lower()]\n",
    "    if speed_col:\n",
    "        sns.lineplot(data=subset, x=subset.index, y=speed_col[0], ax=axes[2], color='green')\n",
    "        axes[2].set_ylabel(\"Solar Wind Speed (km/s)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example: St. Patrick's Day Storm 2015\n",
    "plot_storm_event(df_final, '2015-03-15', '2015-03-20')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aurora-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
